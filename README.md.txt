Dans cet atelier, nous avons exploré plusieurs modèles de Vision par Ordinateur pour la classification d'images avec le jeu de données MNIST. Voici un récapitulatif simple des résultats :

Partie 1 : Classificateur CNN et Faster R-CNN

Classificateur CNN :

Accuracy: 0.9893
F1 Score: 0.9999999949911427
Loss: 0.03232292616219893
Training time: 464.2080121040344 second

Faster R-CNN :

Accuracy: 0.9875
F1 Score: 0.9999999945766359
Training time: 738.6010451316833 seconds

Fine-tuning de VGG16 et AlexNet :

VGG16 (Fine-tuned) :

Accuracy: 0.9883
F1 Score: 0.9999999947463246
Loss: 0.0337651418562467
Training time: 572.9508428573608 seconds

AlexNet (Fine-tuned) :

Accuracy: 0.9818
F1 Score: 0.9999999926019637
Loss: 0.053976701213679886
Training time: 520.3600213527679 seconds

Partie 2 : Vision Transformer (ViT)

Vision Transformer (ViT):

Accuracy: 99.1%
F1 Score: 0.992
Loss: 0.035
Training Time: 30 minutes

Conclusion

Meilleur modèle : ViT avec la plus haute précision et le F1 Score.
Autres observations : VGG16 performant après fine-tuning.
Temps d'entraînement : Varie, ViT prend le plus de temps, CNN le moins.
Cet atelier a été une plongée intéressante dans le monde des modèles de Vision par Ordinateur. N'hésitez pas à explorer davantage selon vos projets et besoins spécifiques. 
